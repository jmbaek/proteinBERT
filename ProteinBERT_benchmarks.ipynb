{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProtBert-MS-FineTuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmbaek/proteinBERT/blob/main/ProteinBERT_benchmarks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNpJNyy4jH6N"
      },
      "source": [
        "**1. Check the GPU device**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7L3UPGazrl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68428910-ac5e-44a9-f694-5e3f9a58aa2f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 30 12:26:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAtbQQ-0jS1K"
      },
      "source": [
        "**2. Load necessry libraries including huggingface transformers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_PhBmySIlsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745bd200-a5b4-4a5e-a5c9-5c8a1ca38064"
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 37.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 30.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/* -P /content/protein_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B7Up7il7Cbw",
        "outputId": "d5da72f4-cc27-420d-d378-57de2c1531c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-31 01:16:05--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/*\n",
            "           => ‘/content/protein_data/.listing’\n",
            "Resolving ftp.cs.huji.ac.il (ftp.cs.huji.ac.il)... 132.65.116.15\n",
            "Connecting to ftp.cs.huji.ac.il (ftp.cs.huji.ac.il)|132.65.116.15|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /users/nadavb/protein_bert/protein_benchmarks ... done.\n",
            "==> PASV ... done.    ==> LIST ... done.\n",
            "\n",
            ".listing                [ <=>                ]   2.15K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-03-31 01:16:08 (481 KB/s) - ‘/content/protein_data/.listing’ saved [2197]\n",
            "\n",
            "Removed ‘/content/protein_data/.listing’.\n",
            "--2022-03-31 01:16:08--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/PhosphositePTM.test.csv\n",
            "           => ‘/content/protein_data/PhosphositePTM.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR PhosphositePTM.test.csv ... done.\n",
            "Length: 10368100 (9.9M)\n",
            "\n",
            "PhosphositePTM.test 100%[===================>]   9.89M  1.62MB/s    in 11s     \n",
            "\n",
            "2022-03-31 01:16:20 (912 KB/s) - ‘/content/protein_data/PhosphositePTM.test.csv’ saved [10368100]\n",
            "\n",
            "--2022-03-31 01:16:20--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/PhosphositePTM.train.csv\n",
            "           => ‘/content/protein_data/PhosphositePTM.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR PhosphositePTM.train.csv ... done.\n",
            "Length: 52737228 (50M)\n",
            "\n",
            "PhosphositePTM.trai 100%[===================>]  50.29M  3.73MB/s    in 33s     \n",
            "\n",
            "2022-03-31 01:16:53 (1.55 MB/s) - ‘/content/protein_data/PhosphositePTM.train.csv’ saved [52737228]\n",
            "\n",
            "--2022-03-31 01:16:53--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/PhosphositePTM.valid.csv\n",
            "           => ‘/content/protein_data/PhosphositePTM.valid.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR PhosphositePTM.valid.csv ... done.\n",
            "Length: 5813646 (5.5M)\n",
            "\n",
            "PhosphositePTM.vali 100%[===================>]   5.54M   906KB/s    in 8.9s    \n",
            "\n",
            "2022-03-31 01:17:03 (634 KB/s) - ‘/content/protein_data/PhosphositePTM.valid.csv’ saved [5813646]\n",
            "\n",
            "--2022-03-31 01:17:03--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/ProFET_NP_SP_Cleaved.test.csv\n",
            "           => ‘/content/protein_data/ProFET_NP_SP_Cleaved.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR ProFET_NP_SP_Cleaved.test.csv ... done.\n",
            "Length: 129360 (126K)\n",
            "\n",
            "ProFET_NP_SP_Cleave 100%[===================>] 126.33K   156KB/s    in 0.8s    \n",
            "\n",
            "2022-03-31 01:17:05 (156 KB/s) - ‘/content/protein_data/ProFET_NP_SP_Cleaved.test.csv’ saved [129360]\n",
            "\n",
            "--2022-03-31 01:17:05--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/ProFET_NP_SP_Cleaved.train.csv\n",
            "           => ‘/content/protein_data/ProFET_NP_SP_Cleaved.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR ProFET_NP_SP_Cleaved.train.csv ... done.\n",
            "Length: 963990 (941K)\n",
            "\n",
            "ProFET_NP_SP_Cleave 100%[===================>] 941.40K   346KB/s    in 2.7s    \n",
            "\n",
            "2022-03-31 01:17:08 (346 KB/s) - ‘/content/protein_data/ProFET_NP_SP_Cleaved.train.csv’ saved [963990]\n",
            "\n",
            "--2022-03-31 01:17:08--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/ProFET_NP_SP_Cleaved.valid.csv\n",
            "           => ‘/content/protein_data/ProFET_NP_SP_Cleaved.valid.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR ProFET_NP_SP_Cleaved.valid.csv ... done.\n",
            "Length: 111179 (109K)\n",
            "\n",
            "ProFET_NP_SP_Cleave 100%[===================>] 108.57K   138KB/s    in 0.8s    \n",
            "\n",
            "2022-03-31 01:17:10 (138 KB/s) - ‘/content/protein_data/ProFET_NP_SP_Cleaved.valid.csv’ saved [111179]\n",
            "\n",
            "--2022-03-31 01:17:10--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/disorder_secondary_structure.test.csv\n",
            "           => ‘/content/protein_data/disorder_secondary_structure.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR disorder_secondary_structure.test.csv ... done.\n",
            "Length: 289756 (283K)\n",
            "\n",
            "disorder_secondary_ 100%[===================>] 282.96K   200KB/s    in 1.4s    \n",
            "\n",
            "2022-03-31 01:17:12 (200 KB/s) - ‘/content/protein_data/disorder_secondary_structure.test.csv’ saved [289756]\n",
            "\n",
            "--2022-03-31 01:17:12--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/disorder_secondary_structure.train.csv\n",
            "           => ‘/content/protein_data/disorder_secondary_structure.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR disorder_secondary_structure.train.csv ... done.\n",
            "Length: 4460380 (4.3M)\n",
            "\n",
            "disorder_secondary_ 100%[===================>]   4.25M   708KB/s    in 8.4s    \n",
            "\n",
            "2022-03-31 01:17:21 (520 KB/s) - ‘/content/protein_data/disorder_secondary_structure.train.csv’ saved [4460380]\n",
            "\n",
            "--2022-03-31 01:17:21--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/disorder_secondary_structure.valid.csv\n",
            "           => ‘/content/protein_data/disorder_secondary_structure.valid.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR disorder_secondary_structure.valid.csv ... done.\n",
            "Length: 1118212 (1.1M)\n",
            "\n",
            "disorder_secondary_ 100%[===================>]   1.07M   469KB/s    in 2.3s    \n",
            "\n",
            "2022-03-31 01:17:24 (469 KB/s) - ‘/content/protein_data/disorder_secondary_structure.valid.csv’ saved [1118212]\n",
            "\n",
            "--2022-03-31 01:17:24--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/fluorescence.test.csv\n",
            "           => ‘/content/protein_data/fluorescence.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR fluorescence.test.csv ... done.\n",
            "Length: 6965550 (6.6M)\n",
            "\n",
            "fluorescence.test.c 100%[===================>]   6.64M   785KB/s    in 12s     \n",
            "\n",
            "2022-03-31 01:17:37 (574 KB/s) - ‘/content/protein_data/fluorescence.test.csv’ saved [6965550]\n",
            "\n",
            "--2022-03-31 01:17:37--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/fluorescence.train.csv\n",
            "           => ‘/content/protein_data/fluorescence.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR fluorescence.train.csv ... done.\n",
            "Length: 5488939 (5.2M)\n",
            "\n",
            "fluorescence.train. 100%[===================>]   5.23M  1.14MB/s    in 6.2s    \n",
            "\n",
            "2022-03-31 01:17:44 (868 KB/s) - ‘/content/protein_data/fluorescence.train.csv’ saved [5488939]\n",
            "\n",
            "--2022-03-31 01:17:44--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/fluorescence.valid.csv\n",
            "           => ‘/content/protein_data/fluorescence.valid.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR fluorescence.valid.csv ... done.\n",
            "Length: 1372356 (1.3M)\n",
            "\n",
            "fluorescence.valid. 100%[===================>]   1.31M   459KB/s    in 2.9s    \n",
            "\n",
            "2022-03-31 01:17:47 (459 KB/s) - ‘/content/protein_data/fluorescence.valid.csv’ saved [1372356]\n",
            "\n",
            "--2022-03-31 01:17:47--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/remote_homology.test.csv\n",
            "           => ‘/content/protein_data/remote_homology.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR remote_homology.test.csv ... done.\n",
            "Length: 110120 (108K)\n",
            "\n",
            "remote_homology.tes 100%[===================>] 107.54K   131KB/s    in 0.8s    \n",
            "\n",
            "2022-03-31 01:17:49 (131 KB/s) - ‘/content/protein_data/remote_homology.test.csv’ saved [110120]\n",
            "\n",
            "--2022-03-31 01:17:49--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/remote_homology.train.csv\n",
            "           => ‘/content/protein_data/remote_homology.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR remote_homology.train.csv ... done.\n",
            "Length: 2114177 (2.0M)\n",
            "\n",
            "remote_homology.tra 100%[===================>]   2.02M   533KB/s    in 3.9s    \n",
            "\n",
            "2022-03-31 01:17:54 (533 KB/s) - ‘/content/protein_data/remote_homology.train.csv’ saved [2114177]\n",
            "\n",
            "--2022-03-31 01:17:54--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/remote_homology.valid.csv\n",
            "           => ‘/content/protein_data/remote_homology.valid.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR remote_homology.valid.csv ... done.\n",
            "Length: 127732 (125K)\n",
            "\n",
            "remote_homology.val 100%[===================>] 124.74K   155KB/s    in 0.8s    \n",
            "\n",
            "2022-03-31 01:17:55 (155 KB/s) - ‘/content/protein_data/remote_homology.valid.csv’ saved [127732]\n",
            "\n",
            "--2022-03-31 01:17:55--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/scop.test.csv\n",
            "           => ‘/content/protein_data/scop.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR scop.test.csv ... done.\n",
            "Length: 708652 (692K)\n",
            "\n",
            "scop.test.csv       100%[===================>] 692.04K   297KB/s    in 2.3s    \n",
            "\n",
            "2022-03-31 01:17:58 (297 KB/s) - ‘/content/protein_data/scop.test.csv’ saved [708652]\n",
            "\n",
            "--2022-03-31 01:17:58--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/scop.train.csv\n",
            "           => ‘/content/protein_data/scop.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR scop.train.csv ... done.\n",
            "Length: 2818989 (2.7M)\n",
            "\n",
            "scop.train.csv      100%[===================>]   2.69M   577KB/s    in 5.9s    \n",
            "\n",
            "2022-03-31 01:18:05 (467 KB/s) - ‘/content/protein_data/scop.train.csv’ saved [2818989]\n",
            "\n",
            "--2022-03-31 01:18:05--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/secondary_structure.test.csv\n",
            "           => ‘/content/protein_data/secondary_structure.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR secondary_structure.test.csv ... done.\n",
            "Length: 289756 (283K)\n",
            "\n",
            "secondary_structure 100%[===================>] 282.96K   179KB/s    in 1.6s    \n",
            "\n",
            "2022-03-31 01:18:07 (179 KB/s) - ‘/content/protein_data/secondary_structure.test.csv’ saved [289756]\n",
            "\n",
            "--2022-03-31 01:18:07--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/secondary_structure.train.csv\n",
            "           => ‘/content/protein_data/secondary_structure.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR secondary_structure.train.csv ... done.\n",
            "Length: 4460380 (4.3M)\n",
            "\n",
            "secondary_structure 100%[===================>]   4.25M   505KB/s    in 14s     \n",
            "\n",
            "2022-03-31 01:18:22 (322 KB/s) - ‘/content/protein_data/secondary_structure.train.csv’ saved [4460380]\n",
            "\n",
            "--2022-03-31 01:18:22--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/secondary_structure.valid.csv\n",
            "           => ‘/content/protein_data/secondary_structure.valid.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR secondary_structure.valid.csv ... done.\n",
            "Length: 1118212 (1.1M)\n",
            "\n",
            "secondary_structure 100%[===================>]   1.07M   251KB/s    in 4.9s    \n",
            "\n",
            "2022-03-31 01:18:27 (225 KB/s) - ‘/content/protein_data/secondary_structure.valid.csv’ saved [1118212]\n",
            "\n",
            "--2022-03-31 01:18:27--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/signalP_binary.test.csv\n",
            "           => ‘/content/protein_data/signalP_binary.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR signalP_binary.test.csv ... done.\n",
            "Length: 302703 (296K)\n",
            "\n",
            "signalP_binary.test 100%[===================>] 295.61K   153KB/s    in 1.9s    \n",
            "\n",
            "2022-03-31 01:18:30 (153 KB/s) - ‘/content/protein_data/signalP_binary.test.csv’ saved [302703]\n",
            "\n",
            "--2022-03-31 01:18:30--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/signalP_binary.train.csv\n",
            "           => ‘/content/protein_data/signalP_binary.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR signalP_binary.train.csv ... done.\n",
            "Length: 1210678 (1.2M)\n",
            "\n",
            "signalP_binary.trai 100%[===================>]   1.15M   260KB/s    in 5.2s    \n",
            "\n",
            "2022-03-31 01:18:36 (229 KB/s) - ‘/content/protein_data/signalP_binary.train.csv’ saved [1210678]\n",
            "\n",
            "--2022-03-31 01:18:36--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/stability.test.csv\n",
            "           => ‘/content/protein_data/stability.test.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR stability.test.csv ... done.\n",
            "Length: 794974 (776K)\n",
            "\n",
            "stability.test.csv  100%[===================>] 776.34K   219KB/s    in 3.5s    \n",
            "\n",
            "2022-03-31 01:18:40 (219 KB/s) - ‘/content/protein_data/stability.test.csv’ saved [794974]\n",
            "\n",
            "--2022-03-31 01:18:40--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/stability.train.csv\n",
            "           => ‘/content/protein_data/stability.train.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR stability.train.csv ... done.\n",
            "Length: 3438868 (3.3M)\n",
            "\n",
            "stability.train.csv 100%[===================>]   3.28M   451KB/s    in 10s     \n",
            "\n",
            "2022-03-31 01:18:51 (332 KB/s) - ‘/content/protein_data/stability.train.csv’ saved [3438868]\n",
            "\n",
            "--2022-03-31 01:18:51--  ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks/stability.valid.csv\n",
            "           => ‘/content/protein_data/stability.valid.csv’\n",
            "==> CWD not required.\n",
            "==> PASV ... done.    ==> RETR stability.valid.csv ... done.\n",
            "Length: 173127 (169K)\n",
            "\n",
            "stability.valid.csv 100%[===================>] 169.07K   138KB/s    in 1.2s    \n",
            "\n",
            "2022-03-31 01:18:53 (138 KB/s) - ‘/content/protein_data/stability.valid.csv’ saved [173127]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "4Z5qTdT4jerN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nadavbra/protein_bert.git\n",
        "!git clone https://github.com/nadavbra/shared_utils.git\n",
        "!cp -R protein_bert/proteinbert/ /usr/lib/python3.7/proteinbert/\n",
        "!cp -R shared_utils/ /usr/lib/python3.7/proteinbert/shared_utils/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2uNYbJIj4d5",
        "outputId": "07dcf750-dad2-4379-cc04-e21a149a1e62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'protein_bert' already exists and is not an empty directory.\n",
            "Cloning into 'shared_utils'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 48 (delta 26), reused 37 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (48/48), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BENCHMARKS_DIR = '/content/protein_data/'"
      ],
      "metadata": {
        "id": "mCBo6abMjF0e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune the model for the signal peptide benchmark"
      ],
      "metadata": {
        "id": "LIiPRae4jmQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
        "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
        "\n",
        "BENCHMARK_NAME = 'signalP_binary'\n",
        "\n",
        "# A local (non-global) bianry output\n",
        "OUTPUT_TYPE = OutputType(False, 'binary')\n",
        "UNIQUE_LABELS = [0, 1]\n",
        "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
        "\n",
        "\n",
        "# Loading the dataset\n",
        "\n",
        "train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
        "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
        "train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.1, random_state = 0)\n",
        "\n",
        "test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
        "test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
        "\n",
        "print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
        "\n",
        "\n",
        "# Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
        "\n",
        "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
        "\n",
        "# get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
        "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
        "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
        "\n",
        "training_callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
        "    keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
        "]\n",
        "\n",
        "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
        "        seq_len = 512, batch_size = 32, max_epochs_per_stage = 40, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n",
        "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n",
        "\n",
        "\n",
        "# Evaluating the performance on the test-set\n",
        "\n",
        "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set['seq'], test_set['label'], \\\n",
        "        start_seq_len = 512, start_batch_size = 32)\n",
        "\n",
        "print('Test-set performance:')\n",
        "display(results)\n",
        "\n",
        "print('Confusion matrix:')\n",
        "display(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXSrUz8QjLEF",
        "outputId": "b3d640f7-1f46-4bdc-dd81-0dc127e02f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14945 training set records, 1661 validation set records, 4152 test set records.\n",
            " Local model dump file /root/proteinbert_models/default.pkl doesn't exist. Will download ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/epoch_92400_sample_23500000.pkl into /root/proteinbert_models. Please approve or reject this (to exit and potentially call the function again with different parameters).\n",
            "Do you approve downloadig the file into the specified directory? Please specify \"Yes\" or \"No\":Yes\n",
            "Downloaded file: /root/proteinbert_models/epoch_92400_sample_23500000.pkl\n",
            "Created: /root/proteinbert_models/default.pkl\n",
            "[2022_03_31-01:51:51] Training set: Filtered out 0 of 14945 (0.0%) records of lengths exceeding 510.\n",
            "[2022_03_31-01:51:52] Validation set: Filtered out 0 of 1661 (0.0%) records of lengths exceeding 510.\n",
            "[2022_03_31-01:51:52] Training with frozen pretrained layers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "468/468 [==============================] - 42s 53ms/step - loss: 0.0956 - val_loss: 0.0652 - lr: 0.0100\n",
            "Epoch 2/40\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.0749\n",
            "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "468/468 [==============================] - 22s 48ms/step - loss: 0.0749 - val_loss: 0.0705 - lr: 0.0100\n",
            "Epoch 3/40\n",
            "468/468 [==============================] - 23s 48ms/step - loss: 0.0623 - val_loss: 0.0636 - lr: 0.0025\n",
            "Epoch 4/40\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.0568\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "468/468 [==============================] - 22s 48ms/step - loss: 0.0568 - val_loss: 0.0694 - lr: 0.0025\n",
            "Epoch 5/40\n",
            "468/468 [==============================] - 23s 48ms/step - loss: 0.0555 - val_loss: 0.0632 - lr: 6.2500e-04\n",
            "Epoch 6/40\n",
            "468/468 [==============================] - 23s 49ms/step - loss: 0.0533 - val_loss: 0.0617 - lr: 6.2500e-04\n",
            "Epoch 7/40\n",
            "468/468 [==============================] - 23s 49ms/step - loss: 0.0520 - val_loss: 0.0599 - lr: 6.2500e-04\n",
            "Epoch 8/40\n",
            "468/468 [==============================] - ETA: 0s - loss: 0.0546\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "468/468 [==============================] - 23s 49ms/step - loss: 0.0546 - val_loss: 0.0610 - lr: 6.2500e-04\n",
            "Epoch 9/40\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.0515\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "468/468 [==============================] - 23s 49ms/step - loss: 0.0515 - val_loss: 0.0601 - lr: 1.5625e-04\n",
            "[2022_03_31-01:55:43] Training the entire fine-tuned model...\n",
            "[2022_03_31-01:55:52] Incompatible number of optimizer weights - will not initialize them.\n",
            "Epoch 1/40\n",
            "354/468 [=====================>........] - ETA: 13s - loss: 0.0623"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZHO-2ZSDrHjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run all benchmarks"
      ],
      "metadata": {
        "id": "H0UO3O7CrWWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len, log\n",
        "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
        "\n",
        "BENCHMARKS = [\n",
        "    # name, output_type\n",
        "    ('signalP_binary', OutputType(False, 'binary')),\n",
        "    ('fluorescence', OutputType(False, 'numeric')),\n",
        "    ('remote_homology', OutputType(False, 'categorical')),\n",
        "    ('stability', OutputType(False, 'numeric')),\n",
        "    ('scop', OutputType(False, 'categorical')),\n",
        "    ('secondary_structure', OutputType(True, 'categorical')),\n",
        "    ('disorder_secondary_structure', OutputType(True, 'binary')),\n",
        "    ('ProFET_NP_SP_Cleaved', OutputType(False, 'binary')),\n",
        "    ('PhosphositePTM', OutputType(True, 'binary')),\n",
        "]\n",
        "\n",
        "settings = {\n",
        "    'max_dataset_size': None,\n",
        "    'max_epochs_per_stage': 40,\n",
        "    'seq_len': 512,\n",
        "    'batch_size': 32,\n",
        "    'final_epoch_seq_len': 1024,\n",
        "    'initial_lr_with_frozen_pretrained_layers': 1e-02,\n",
        "    'initial_lr_with_all_layers': 1e-04,\n",
        "    'final_epoch_lr': 1e-05,\n",
        "    'dropout_rate': 0.5,\n",
        "    'training_callbacks': [\n",
        "        keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
        "        keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
        "    ],\n",
        "}\n",
        "\n",
        "####### Uncomment for debug mode\n",
        "# settings['max_dataset_size'] = 500\n",
        "# settings['max_epochs_per_stage'] = 1\n",
        "\n",
        "def run_benchmark(benchmark_name, pretraining_model_generator, input_encoder, pretraining_model_manipulation_function = None):\n",
        "    \n",
        "    log('========== %s ==========' % benchmark_name)  \n",
        "    \n",
        "    output_type = get_benchmark_output_type(benchmark_name)\n",
        "    log('Output type: %s' % output_type)\n",
        "    \n",
        "    train_set, valid_set, test_set = load_benchmark_dataset(benchmark_name)        \n",
        "    log(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
        "    \n",
        "    if settings['max_dataset_size'] is not None:\n",
        "        log('Limiting the training, validation and test sets to %d records each.' % settings['max_dataset_size'])\n",
        "        train_set = train_set.sample(min(settings['max_dataset_size'], len(train_set)), random_state = 0)\n",
        "        valid_set = valid_set.sample(min(settings['max_dataset_size'], len(valid_set)), random_state = 0)\n",
        "        test_set = test_set.sample(min(settings['max_dataset_size'], len(test_set)), random_state = 0)\n",
        "    \n",
        "    if output_type.is_seq or output_type.is_categorical:\n",
        "        train_set['label'] = train_set['label'].astype(str)\n",
        "        valid_set['label'] = valid_set['label'].astype(str)\n",
        "        test_set['label'] = test_set['label'].astype(str)\n",
        "    else:\n",
        "        train_set['label'] = train_set['label'].astype(float)\n",
        "        valid_set['label'] = valid_set['label'].astype(float)\n",
        "        test_set['label'] = test_set['label'].astype(float)\n",
        "        \n",
        "    if output_type.is_categorical:\n",
        "        \n",
        "        if output_type.is_seq:\n",
        "            unique_labels = sorted(set.union(*train_set['label'].apply(set)) | set.union(*valid_set['label'].apply(set)) | \\\n",
        "                    set.union(*test_set['label'].apply(set)))\n",
        "        else:\n",
        "            unique_labels = sorted(set(train_set['label'].unique()) | set(valid_set['label'].unique()) | set(test_set['label'].unique()))\n",
        "            \n",
        "        log('%d unique lebels.' % len(unique_labels))\n",
        "    elif output_type.is_binary:\n",
        "        unique_labels = [0, 1]\n",
        "    else:\n",
        "        unique_labels = None\n",
        "        \n",
        "    output_spec = OutputSpec(output_type, unique_labels)\n",
        "    model_generator = FinetuningModelGenerator(pretraining_model_generator, output_spec, pretraining_model_manipulation_function = \\\n",
        "            pretraining_model_manipulation_function, dropout_rate = settings['dropout_rate'])\n",
        "    finetune(model_generator, input_encoder, output_spec, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
        "            seq_len = settings['seq_len'], batch_size = settings['batch_size'], max_epochs_per_stage = settings['max_epochs_per_stage'], \\\n",
        "            lr = settings['initial_lr_with_all_layers'], begin_with_frozen_pretrained_layers = True, lr_with_frozen_pretrained_layers = \\\n",
        "            settings['initial_lr_with_frozen_pretrained_layers'], n_final_epochs = 1, final_seq_len = settings['final_epoch_seq_len'], \\\n",
        "            final_lr = settings['final_epoch_lr'], callbacks = settings['training_callbacks'])\n",
        "    \n",
        "    for dataset_name, dataset in [('Training-set', train_set), ('Validation-set', valid_set), ('Test-set', test_set)]:\n",
        "        \n",
        "        log('*** %s performance: ***' % dataset_name)\n",
        "        results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, output_spec, dataset['seq'], dataset['label'], \\\n",
        "                start_seq_len = settings['seq_len'], start_batch_size = settings['batch_size'])\n",
        "    \n",
        "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "            display(results)\n",
        "        \n",
        "        if confusion_matrix is not None:\n",
        "            with pd.option_context('display.max_rows', 16, 'display.max_columns', 10):\n",
        "                log('Confusion matrix:')\n",
        "                display(confusion_matrix)\n",
        "                \n",
        "    return model_generator\n",
        "\n",
        "def load_benchmark_dataset(benchmark_name):\n",
        "    \n",
        "    train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % benchmark_name)\n",
        "    valid_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.valid.csv' % benchmark_name)\n",
        "    test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % benchmark_name)\n",
        "    \n",
        "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
        "    test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
        "          \n",
        "    if os.path.exists(valid_set_file_path):\n",
        "        valid_set = pd.read_csv(valid_set_file_path).dropna().drop_duplicates()\n",
        "    else:\n",
        "        log(f'Validation set {valid_set_file_path} missing. Splitting training set instead.')\n",
        "        train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.1, random_state = 0)\n",
        "    \n",
        "    return train_set, valid_set, test_set\n",
        "\n",
        "def get_benchmark_output_type(benchmark_name):\n",
        "    for name, output_type in BENCHMARKS:\n",
        "        if name == benchmark_name:\n",
        "            return output_type\n",
        "        \n",
        "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
        "\n",
        "for benchmark_name, _ in BENCHMARKS:\n",
        "    run_benchmark(benchmark_name, pretrained_model_generator, input_encoder, pretraining_model_manipulation_function = \\\n",
        "            get_model_with_hidden_layers_as_outputs)\n",
        "        \n",
        "log('Done.')"
      ],
      "metadata": {
        "id": "dcOM4ksHjK5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "irwNNwXhjVYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Visualizing the attention layers\n",
        "\n",
        "You can run this only after you have fine-tuned the model on a benchmark (e.g. signal peptide) and obtained model_generator.\n"
      ],
      "metadata": {
        "id": "qoqmf8z3rgJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BENCHMARK_DISPLAY_NAME = 'Signal peptide'\n",
        "\n",
        "TEST_SET_FILE_PATH = '/cs/phd/nadavb/my_public_ftp_site/protein_bert/protein_benchmarks/signalP_binary.train.csv'\n",
        "IDEAL_LEN = 80\n",
        "\n",
        "def calculate_attentions(model, input_encoder, seq, seq_len = None):\n",
        "    \n",
        "    from tensorflow.keras import backend as K\n",
        "    from proteinbert.tokenization import index_to_token\n",
        "    \n",
        "    if seq_len is None:\n",
        "        seq_len = len(seq) + 2\n",
        "    \n",
        "    X = input_encoder.encode_X([seq], seq_len)\n",
        "    (X_seq,), _ = X\n",
        "    seq_tokens = list(map(index_to_token.get, X_seq))\n",
        "\n",
        "    model_inputs = [layer.input for layer in model.layers if 'InputLayer' in str(type(layer))][::-1]\n",
        "    model_attentions = [layer.calculate_attention(layer.input) for layer in model.layers if 'GlobalAttention' in str(type(layer))]\n",
        "    invoke_model_attentions = K.function(model_inputs, model_attentions)\n",
        "    attention_values = invoke_model_attentions(X)\n",
        "    \n",
        "    attention_labels = []\n",
        "    merged_attention_values = []\n",
        "\n",
        "    for attention_layer_index, attention_layer_values in enumerate(attention_values):\n",
        "        for head_index, head_values in enumerate(attention_layer_values):\n",
        "            attention_labels.append('Attention %d - head %d' % (attention_layer_index + 1, head_index + 1))\n",
        "            merged_attention_values.append(head_values)\n",
        "\n",
        "    attention_values = np.array(merged_attention_values)\n",
        "    \n",
        "    return attention_values, seq_tokens, attention_labels\n",
        "\n",
        "def plot_attention(attention_values, seq_tokens, attention_labels, ax, cmap = 'Reds', vmin = 0, vmax = None, text_value_threshold = 0.1):\n",
        "\n",
        "    heatmap = ax.pcolor(attention_values.transpose(), cmap = cmap, vmin = vmin, vmax = vmax)\n",
        "\n",
        "    ax.set_xticks(np.arange(len(attention_labels)) + 0.5)\n",
        "    ax.set_xticklabels(attention_labels, rotation = 45, ha = 'right', fontsize = 12)\n",
        "    ax.set_yticks(np.arange(len(seq_tokens)) + 0.5)\n",
        "    ax.set_yticklabels(seq_tokens, fontsize = 12)\n",
        "\n",
        "    for i, row in enumerate(attention_values):\n",
        "        for j, value in enumerate(row):\n",
        "            if abs(value) >= text_value_threshold:\n",
        "                add_plus_sign = attention_values.min() < 0 and value > 0\n",
        "                plus_sign = '+' if add_plus_sign else ''\n",
        "                ax.text(i + 0.5, j + 0.5, plus_sign + '%d%%' % (100 * value), color = 'white', ha = 'center', va = 'center', \\\n",
        "                        fontsize = 9, fontweight = 'bold', fontstretch = 'condensed')\n",
        "                \n",
        "test_set = pd.read_csv(TEST_SET_FILE_PATH)\n",
        "chosen_index = ((test_set['seq'].str.len() - IDEAL_LEN).abs()).sort_values().index[0]\n",
        "seq = test_set.loc[chosen_index, 'seq']\n",
        "label = test_set.loc[chosen_index, 'label']\n",
        "                \n",
        "seq_len = len(seq) + 2\n",
        "\n",
        "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
        "model = pretrained_model_generator.create_model(seq_len)\n",
        "pretrained_attention_values, pretrained_seq_tokens, pretrained_attention_labels = calculate_attentions(model, input_encoder, seq, \\\n",
        "        seq_len = seq_len)\n",
        "\n",
        "model = model_generator.create_model(seq_len)\n",
        "finetuned_attention_values, finetuned_seq_tokens, finetuned_attention_labels = calculate_attentions(model, input_encoder, seq, \\\n",
        "        seq_len = seq_len)\n",
        "assert finetuned_seq_tokens == pretrained_seq_tokens\n",
        "assert finetuned_attention_labels == pretrained_attention_labels[:len(finetuned_attention_labels)]\n",
        "\n",
        "fig, axes = plt.subplots(ncols = 4, figsize = (20, 0.2 * seq_len), gridspec_kw = dict(width_ratios = [1, 5, 1, 5]))\n",
        "fig.subplots_adjust(wspace = 0.3)\n",
        "\n",
        "axes[0].barh(np.arange(seq_len), 100 * pretrained_attention_values.sum(axis = 0), color = '#EC7063')\n",
        "axes[0].set_ylim((-0.5, seq_len - 0.5))\n",
        "axes[0].set_yticks([])\n",
        "axes[0].invert_xaxis()\n",
        "axes[0].set_xlabel('Total atten. %', fontsize = 14)\n",
        "\n",
        "vmax = pretrained_attention_values.max()\n",
        "plot_attention(pretrained_attention_values, pretrained_seq_tokens, pretrained_attention_labels, axes[1], cmap = 'Reds', vmax = vmax, \\\n",
        "        text_value_threshold = 0.05)\n",
        "axes[1].set_title('Only pre-training', fontsize = 16)\n",
        "\n",
        "axes[2].barh(np.arange(seq_len), 100 * (finetuned_attention_values - pretrained_attention_values).sum(axis = 0), color = '#28B463')\n",
        "axes[2].set_ylim((-0.5, seq_len - 0.5))\n",
        "axes[2].set_yticks([])\n",
        "axes[2].invert_xaxis()\n",
        "axes[2].set_xlabel('Total atten. % diff', fontsize = 14)\n",
        "\n",
        "attention_diff = finetuned_attention_values - pretrained_attention_values[:len(finetuned_attention_labels), :]\n",
        "vmax = np.abs(attention_diff).max()\n",
        "plot_attention(attention_diff, finetuned_seq_tokens, finetuned_attention_labels, axes[3], cmap = 'PiYG', vmin = -vmax, vmax = vmax, \\\n",
        "        text_value_threshold = 0.03)\n",
        "axes[3].set_title('%s fine-tuning' % BENCHMARK_DISPLAY_NAME, fontsize = 16)\n",
        "\n",
        "print(seq, label)"
      ],
      "metadata": {
        "id": "Z7-qV7lYjVM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tgQpTv6xrkJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zRHEYfkHrkee"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}